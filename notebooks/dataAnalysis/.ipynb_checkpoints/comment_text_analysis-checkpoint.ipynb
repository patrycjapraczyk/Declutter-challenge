{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Load data and import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from helpers.data_preprocessing import DataProcesser\n",
    "\n",
    "data = pd.read_csv(\"./../../data/train_set_0520.csv\", usecols=['comment', 'non-information'])\n",
    "\n",
    "comments = data['comment'].apply(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Preprocess data:\n",
    "1. remove all special characters and accents\n",
    "2. turn all characters into lower case\n",
    "3. stemming --> put the word into its most basic form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    implnot taken from link comsunjavafxscenecontr...\n",
       "1             iconsettooltiptextprintedviewmodelgetloc\n",
       "2    synchron chang of the underli date valu with t...\n",
       "3    ask if the user realli want to close the given...\n",
       "4                                           css inform\n",
       "dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp = DataProcesser()\n",
    "\n",
    "comments = dp.preprocess(comments)\n",
    "comments = pd.Series(comments)\n",
    "\n",
    "comments.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Split words and put them into a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['implnot',\n",
       " 'taken',\n",
       " 'from',\n",
       " 'link',\n",
       " 'comsunjavafxscenecontrolbehaviortextareabehaviorcontextmenurequestedjavafxsceneinputcontextmenuev',\n",
       " 'iconsettooltiptextprintedviewmodelgetloc',\n",
       " 'synchron',\n",
       " 'chang',\n",
       " 'of',\n",
       " 'the',\n",
       " 'underli',\n",
       " 'date',\n",
       " 'valu',\n",
       " 'with',\n",
       " 'the']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_comments = \" \".join(comments)\n",
    "split_comments = split_comments.split()\n",
    "split_comments[0:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "count word frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'implnot': 2,\n",
       " 'taken': 10,\n",
       " 'from': 105,\n",
       " 'link': 161,\n",
       " 'comsunjavafxscenecontrolbehaviortextareabehaviorcontextmenurequestedjavafxsceneinputcontextmenuev': 1,\n",
       " 'iconsettooltiptextprintedviewmodelgetloc': 1,\n",
       " 'synchron': 1,\n",
       " 'chang': 99,\n",
       " 'of': 330,\n",
       " 'the': 1461,\n",
       " 'underli': 3,\n",
       " 'date': 18,\n",
       " 'valu': 60,\n",
       " 'with': 105,\n",
       " 'temporalaccessorvalu': 1}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "counted_comments = Counter(split_comments)\n",
    "{k: counted_comments[k] for k in list(counted_comments)[:15]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "15 most common words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 1461),\n",
       " ('to', 587),\n",
       " ('a', 455),\n",
       " ('is', 353),\n",
       " ('of', 330),\n",
       " ('thi', 311),\n",
       " ('in', 279),\n",
       " ('and', 272),\n",
       " ('if', 263),\n",
       " ('for', 258),\n",
       " ('entri', 215),\n",
       " ('it', 207),\n",
       " ('file', 201),\n",
       " ('be', 185),\n",
       " ('link', 161)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_occur = counted_comments.most_common(15)\n",
    "most_occur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "remove_stopwords() missing 1 required positional argument: 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-c83f10fff7f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcomments_cleaned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataProcesser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove_stopwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcomments_cleaned\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: remove_stopwords() missing 1 required positional argument: 'text'"
     ]
    }
   ],
   "source": [
    "comments_cleaned = list(map(DataProcesser.remove_stopwords, comments))\n",
    "comments_cleaned[0:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "most common words after removing stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "split_comments = \" \".join(comments_cleaned)\n",
    "split_comments = split_comments.split()\n",
    "counted_comments = Counter(split_comments)\n",
    "most_occur = counted_comments.most_common(15)\n",
    "most_occur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Word Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Generate a word cloud image\n",
    "comments_cleaned = \" \".join(comments_cleaned)\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "wordcloud1 = WordCloud(width=1600, height=800).generate(comments_cleaned)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Display the generated image:\n",
    "plt.imshow(wordcloud1, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout(pad=0)\n",
    "plt.show()\n",
    "plt.savefig('./comment_wordcloud.png', facecolor='k', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Non-information 'yes' comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data.head()\n",
    "bad_comments = data[data['non-information'] == 'yes']\n",
    "bad_comments = bad_comments['comment'].apply(str)\n",
    "\n",
    "#data cleaning\n",
    "#remove special characters\n",
    "bad_comments = bad_comments.map(DataProcesser.remove_special_characters)\n",
    "#remove accented chars\n",
    "bad_comments = bad_comments.map(DataProcesser.remove_accented_chars)\n",
    "#to lower case\n",
    "bad_comments = bad_comments.map(lambda com : com.lower())\n",
    "\n",
    "#stemming\n",
    "ps = PorterStemmer()\n",
    "bad_comments = [(\" \".join(list(map(ps.stem, comment.split())))) for comment in bad_comments]\n",
    "\n",
    "#remove stopwords\n",
    "bad_comments = list(map(DataProcesser.remove_stopwords, bad_comments))\n",
    "bad_comments[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What words are most common among the non-information 'yes' comments?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#split into words\n",
    "split_comments = \" \".join(bad_comments)\n",
    "split_comments = split_comments.split()\n",
    "counted_comments = Counter(split_comments)\n",
    "{k: counted_comments[k] for k in list(counted_comments)[:15]}\n",
    "most_occur = counted_comments.most_common(15)\n",
    "most_occur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word Cloud of non-information 'yes' comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Generate a word cloud image\n",
    "comments_cleaned = \" \".join(bad_comments)\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "wordcloud1 = WordCloud(width=1600, height=800).generate(comments_cleaned)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Display the generated image:\n",
    "plt.imshow(wordcloud1, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout(pad=0)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non-information 'no' comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data.head()\n",
    "good_comments = data[data['non-information'] == 'no']\n",
    "good_comments = good_comments['comment'].apply(str)\n",
    "\n",
    "#data cleaning\n",
    "#remove special characters\n",
    "good_comments = good_comments.map(DataProcesser.remove_special_characters)\n",
    "#remove accented chars\n",
    "good_comments = good_comments.map(DataProcesser.remove_accented_chars)\n",
    "#to lower case\n",
    "good_comments = good_comments.map(lambda com : com.lower())\n",
    "\n",
    "#stemming\n",
    "ps = PorterStemmer()\n",
    "good_comments = [(\" \".join(list(map(ps.stem, comment.split())))) for comment in good_comments]\n",
    "\n",
    "#remove stopwords\n",
    "good_comments = list(map(DataProcesser.remove_stopwords, good_comments))\n",
    "good_comments[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What words are most common among the non-information 'no' comments?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#split into words\n",
    "split_comments = \" \".join(good_comments)\n",
    "split_comments = split_comments.split()\n",
    "counted_comments = Counter(split_comments)\n",
    "{k: counted_comments[k] for k in list(counted_comments)[:15]}\n",
    "most_occur = counted_comments.most_common(15)\n",
    "most_occur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non-information 'no' comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Generate a word cloud image\n",
    "comments_cleaned = \" \".join(good_comments)\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "wordcloud1 = WordCloud(width=1600, height=800).generate(comments_cleaned)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Display the generated image:\n",
    "plt.imshow(wordcloud1, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout(pad=0)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
