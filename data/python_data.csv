,comment,non-information,code,functional_type
0,Set some global variables,yes,try: import agorartc RTC = agorartc.createRtcEngineBridge() eventHandler = agorartc.RtcEngineEventHandlerBase() RTC.initEventHandler(eventHandler),assignment
1,0xFFFFFFFE will exclude Chinese servers from Agora's servers.,no,"RTC.initialize(Clubhouse.AGORA_KEY, None, agorartc.AREA_CODE_GLOB & 0xFFFFFFFE)",method_call
2,(Clubhouse) -> NoneType Main function for chat,yes,def chat_main(client),method_declaration
3,Delete event.,yes,"def delete_event(self, event_id, user_ids=None, club_id=None, is_member_only=False, event_hashid=None, description=None, time_start_epoch=None, name=None): data = { ""user_ids"": user_ids, ""club_id"": club_id, ""is_member_only"": is_member_only, ""event_id"": event_id, ""event_hashid"": event_hashid, ""description"": description, ""time_start_epoch"": time_start_epoch, ""name"": name } req = requests.post(f""{self.API_URL}/delete_event"", headers=self.HEADERS, json=data) return req.json()",method_declaration
4,Join the given channel,yes,"def join_channel(self, channel, attribution_source=""feed""): data = { ""channel"": channel, ""attribution_source"": attribution_source, ""attribution_details"": ""eyJpc19leHBsb3JlIjpmYWxzZSwicmFuayI6MX0="",} req = requests.post(f""{self.API_URL}/join_channel"", headers=self.HEADERS, json=data) return req.json()",method_declaration
5,"Find the singleton counter for the current scoped graph.  If it doesn't exist, create one.",no,"xla_scope_counter = ops.get_collection(_XLA_SCOPE_KEY) if not xla_scope_counter: xla_scope_counter = _XlaScope(0, 0) ops.add_to_collection(_XLA_SCOPE_KEY, xla_scope_counter) else: xla_scope_counter = xla_scope_counter[0]",assignment
6,Check that the must-compile attribute gets correctly propagated to the created derivatives.,no," self.assertTrue(forward.definition.attr[""_XlaMustCompile""]) self.assertTrue(backward.function_def.attr[""_XlaMustCompile""])",method_call
7,Checking that we crash on an unsupported operation lets us test that the XLA compiler was actually invoked.,no,"def testUnsupportedOps(self): with ops.Graph().as_default() as g: def fn(x): return array_ops.unique(x).y  # Unique is not supported by XLA xla_func = def_function.function(fn, jit_compile=True) inputs = array_ops.placeholder(dtypes.float32, [5]) x = xla_func(inputs) with self.assertRaisesRegex(errors.InvalidArgumentError, ""not compilable""): with session.Session(graph=g) as sess: sess.run(x, feed_dict={inputs: [1, 2, 2, 3, 3]})",method_declaration
8,Just for authenticating the user.,yes,"if not result['success']: print(f""[-] Error occured during authentication. ({result['error_message']})"") continue break result = None while True: verification_code = input(""[.] Please enter the SMS verification code (1234, 0000, ...) > "") result = client.complete_phone_number_auth(user_phone_number, verification_code) if not result['success']: print(f""[-] Error occured during authentication. ({result['error_message']})"") continue break user_id = result['user_profile']['user_id'] user_token = result['auth_token'] user_device = client.HEADERS.get(""CH-DeviceId"") write_config(user_id, user_token, user_device) print(""[.] Writing configuration file complete."") if result['is_waitlisted']: print(""[!] You're still on the waitlist. Find your friends to get yourself in."") return client = Clubhouse( user_id=user_id, user_token=user_token, user_device=user_device ) if result['is_onboarding']: process_onboarding(client) return",method_declaration
9,recursive Fibonacci,yes,"def fib(i): if i <= 2: return 1; else: f = fib(i-1) + fib(i-2) print('calc', i) return f print(fib(6))",method_declaration
10,Check response status and throw corresponding exception on failure,yes,"def check_response_status(self, response): code = response.status_code if code < 200 or code >= 300: try: message = response.json()[""description""] except Exception: message = "" "" logger.debug(f'Error received: status code: {code}, message: ""{message}""') if code == 400: raise BadRequestException(response) elif response.status_code == 401: raise AuthenticationException() elif response.status_code == 403: raise AuthorizationException() elif response.status_code == 404: if message != "" "": raise NotFoundException(message) else: raise NotFoundException elif response.status_code == 429: raise OverLimitException(message) elif response.status_code == 502: raise BadGatewayException() elif response.status_code == 504: raise GatewayTimeoutException(message) elif response.status_code == 423: raise LockedException(message) elif 500 <= response.status_code < 600: if ""Server under maintenance"" in response.content.decode(): raise ServerException( ""Server under maintenance, please try again later."" ) else: raise ServerException() else: msg = ""An error occurred. Server response: {}"".format( response.status_code ) raise HubException(message=msg)",method_declaration
11,Joins given arguments into a url. Trailing but not leading slashes are stripped for each argument.,yes,"def urljoin(*args): return ""/"".join(map(lambda x: str(x).strip(""/""), args))",method_declaration
12,Controlling Hub through rest api,yes,"class HubControlClient(HubHttpClient): def __init__(self): super().__init__() self.details = self.get_config() def get_dataset_path(self, tag): try: dataset = self.request( ""GET"", config.GET_DATASET_PATH_SUFFIX, params={""tag"": tag}, endpoint=config.HUB_REST_ENDPOINT, ).json() except NotFoundException: dataset = None return dataset def get_credentials(self): if self.auth_header is None: token = AuthClient().get_access_token(username=""public"", password="""") self.auth_header = f""Bearer {token}"" r = self.request( ""GET"", config.GET_CREDENTIALS_SUFFIX, endpoint=config.HUB_REST_ENDPOINT, ).json() details = { ""_id"": r[""_id""], ""region"": r[""region""], ""session_token"": r[""session_token""], ""access_key"": r[""access_key""], ""secret_key"": r[""secret_key""], ""endpoint"": r[""endpoint""], ""expiration"": r[""expiration""], ""bucket"": r[""bucket""], } self.save_config(details) return details def get_config(self, reset=False): if not os.path.isfile(config.STORE_CONFIG_PATH) or self.auth_header is None: self.get_credentials() with open(config.STORE_CONFIG_PATH) as file: details = file.readlines() details = json.loads("""".join(details)) if float(details[""expiration""]) < time.time() - 36000 or reset: details = self.get_credentials() return details def save_config(self, details): path = Path(config.STORE_CONFIG_PATH) os.makedirs(path.parent, exist_ok=True) with open(config.STORE_CONFIG_PATH, ""w"") as file: file.writelines(json.dumps(details)) def create_dataset_entry(self, username, dataset_name, meta, public=True): try: tag = f""{username}/{dataset_name}"" repo = f""public/{username}"" if public else f""private/{username}"" self.request( ""POST"", config.CREATE_DATASET_SUFFIX, json={ ""tag"": tag, ""repository"": repo, ""public"": public, ""rewrite"": True, }, endpoint=config.HUB_REST_ENDPOINT, ).json() except Exception as e: logger.error( ""Unable to create Dataset entry"" + traceback.format_exc() + str(e) ) def update_dataset_state(self, username, dataset_name, state, progress=0): try: tag = f""{username}/{dataset_name}"" self.request( ""POST"", config.UPDATE_STATE_SUFFIX, json={ ""tag"": tag, ""state"": state, ""progress"": progress, }, endpoint=config.HUB_REST_ENDPOINT, ).json() except Exception as e: logger.error( ""Unable to update Dataset entry state "" + traceback.format_exc() + str(e) ) def delete_dataset_entry(self, username, dataset_name): try: tag = f""{username}/{dataset_name}"" suffix = f""{config.DATASET_SUFFIX}/{tag}"" self.request( ""DELETE"", suffix, endpoint=config.HUB_REST_ENDPOINT, ).json() except Exception as e: logger.error( ""Unable to delete Dataset entry"" + traceback.format_exc() + str(e) )",class_declaration
13,manages access tokens,yes,"class TokenManager: def is_authenticated(cls): return os.path.getsize(config.TOKEN_FILE_PATH) > 10  def set_token(cls, token): logger.debug(f""Putting the key {token} into {config.TOKEN_FILE_PATH}."") path = Path(config.TOKEN_FILE_PATH) os.makedirs(path.parent, exist_ok=True) with open(config.TOKEN_FILE_PATH, ""w"") as f: f.write(token)  def get_token(cls): logger.debug(""Getting token..."") if not os.path.exists(config.TOKEN_FILE_PATH): return None with open(config.TOKEN_FILE_PATH) as f: token = f.read() logger.debug(f""Got the key {token} from {config.TOKEN_FILE_PATH}."") return token  def get_auth_header(cls): logger.debug(""Constructing auth header..."") token = cls.get_token() if token: return f""Bearer {token}"" return None def purge_token(cls): logger.debug(""Purging token..."") if os.path.isfile(config.TOKEN_FILE_PATH): os.remove(config.TOKEN_FILE_PATH)",class_declaration
14," try:token_dict = response.json() except Exception as e: logger.error(""Exception occured while registering token: {}."".format(e)) raise HubException(""Error while registering in. {e}"")",yes,,empty
15,Converts Tensor and its derivatives into a serializable format,yes," def serialize_tensor(tensor): d = copy.deepcopy(tensor.__dict__) d[""type""] = type(tensor).__name__ if hasattr(tensor, ""dtype""): d[""dtype""] = serialize(tensor.dtype) if hasattr(tensor, ""class_labels""): d[""class_labels""] = serialize(tensor.class_labels) return d",method_declaration
16,Converts the input into a serializable format,yes,"def serialize(input): if isinstance(input, Tensor): return serialize_tensor(input) elif isinstance(input, SchemaDict): return serialize_SchemaDict(input) elif isinstance(input, Primitive): return serialize_primitive(input) else: raise TypeError(""Unknown type"", type(input))",method_declaration
17,Converts Primitive into a serializable format,yes,def serialize_primitive(primitive): return str(primitive._dtype),method_declaration
18,Check if provided shape maches mask characteristics,yes,"def _check_shape(self, shape): if len(shape) != 3 or shape[-1] != 1: raise ValueError( ""Wrong mask shape provided, should be of the format (height, width, 1) where height and width are integers or None"" )",method_declaration
19,Validate that next vertex is not already in path,yes,return not any(vertex == next_ver for vertex in path),return
20,initialize start and end of path with starting index,yes,ath[0] = path[-1] = start_index,assignment
21,"n=int(input(""The no. of queens""))",yes,,empty
22,Print all the boards,yes," for board in boards: for column in board: print(column) print("""")",loop
23,Check lower bounds ,yes,lower_flag = (not (i < 0)) and (not (j < 0)) ,conditional
24,Check upper bounds,yes,upper_flag = (i < size) and (j < size),conditional
25,declaring useful variables,yes, length = len(sorted_profit_by_weight) limit = 0 gain = 0 i = 0,assignment
26,Function Call,yes,"calc_profit(profit, weight, max_weight)",method_call
27,until precisely equals to 10^-7 ,yes,while abs(start - mid) > 10 ** -7:,loop
28,augmented matrix,yes,"augmented_mat = np.concatenate((coefficients, vector), axis=1)",var_declaration
29,left shift the bits by unity,yes,result = result << 1,assignment
30,Extended Euclid,yes,"def extended_euclid(a: int, b: int) -> Tuple[int, int]:",method_declaration
31,Implemented below,yes,"(d, t, s) = extended_gcd(n, a) ",method_call
32,"greatest_common_divisor(a,b) function implemented below",yes," assert (c % greatest_common_divisor(a, b) == 0)",method_call
33,Initial value,yes,"(x0, y0) = diophantine(a, b, c)",assignment
34,Create the output image,yes,"img = Image.new(""RGB"", (len(cells[0]), len(cells)))",assignment
35,b16encoded the encoded string,yes,b16encoded = base64.b16encode(encoded),assignment
36,Make sure the supplied data is a bytes-like object,yes,"if not isinstance(data, bytes):",assignment
37,Check if the encoded string contains non base64 characters,yes," if padding: assert all( char in B64_CHARSET for char in encoded_data[:-padding] ), ""Invalid base64 character(s) found.""",conditional
38,Check the padding,yes,"assert len(encoded_data) % 4 == 0 and padding < 3, ""Incorrect padding""",method_call
39,decoded it,yes,"print(base64.a85decode(a85encoded).decode(""utf-8"")) ",method_call
40,a85encoded the encoded string,yes,a85encoded = base64.a85encode(encoded) ,assignment
41,The final result string,yes,"result = """"",assignment
42,Append without encryption if character is not in the alphabet,yes, if character not in alpha: result += character,conditional
43,Cycle through each combination,yes,"for key in range(1, len(alpha) + 1):",loop
44,get user input,yes,"choice = input(""\nWhat would you like to do?: "").strip() or ""4""",assignment
45,Custom frequencies dictionary,yes,frequencies = frequencies_dict,assignment
46,Chi squared statistic values,yes,chi_squared_statistic_values = {},var_declaration
47,cycle through all of the shifts,yes,for shift in range(len(alphabet_letters)):,loop
48,Loop through each letter in the decoded message with the shift,yes,for letter in decrypted_with_shift:,loop
49,Get the amount of times the letter occurs in the message,yes,occurrences = decrypted_with_shift.count(letter),assignment
50,Complete the chi squared statistic formula,yes,chi_letter_value = ((occurrences - expected) ** 2) / expected,assignment
51,Add the data to the chi_squared_statistic_values dictionary,yes,"  chi_squared_statistic_values[shift] = [ chi_squared_statistic, decrypted_with_shift, ]",assignment
52,then we have our last prime to check,yes,plist = primes[:idx],assignment
53,Created the dictionary,yes,pb = {},var_declaration
54,print(temp),yes,,empty
55,loop through each symbol in the message,yes,for symbol in message:,loop
56,Create alphabet list,yes,alphabet = [chr(i + 65) for i in range(26)],assignment
57,Reverse our cipher mappings,yes,"rev_cipher_map = {v: k for k, v in cipher_map.items()}",assignment
58,private field,yes,self.__key = key,assignment
59,precondition,yes,"assert isinstance(key, int) and isinstance(content, str)",conditional
60,This will be returned,yes,ans = [],var_declaration
61,Can change the value,yes,if r > 0.5:,conditional
62,fmt: on,yes,"new_value = """"",var_declaration
63,basically /= 8 without remainder if any,yes,num = math.floor(num / 8),method_call
64,Main function for testing.,yes,"def main() -> None:  # Main function for testing. tree = Node(1) tree.left = Node(2) tree.right = Node(3) tree.left.left = Node(4) tree.left.right = Node(5) tree.left.right.left = Node(6) tree.right.left = Node(7) tree.right.left.left = Node(8) tree.right.left.left.right = Node(9) print(is_full_binary_tree(tree)) print(depth_of_tree(tree)) print(""Tree is: "") display(tree)",method_declaration
65,f it is the right children,yes,if self.is_right(node): ,conditional
66,create a new Node,yes,"new_node = Node(value, None)",assignment
67,if Tree is empty,yes,if self.empty(): ,conditional
68,set its root,yes,self.root = new_node,assignment
69,We insert the new node in a leaf,yes,parent_node.left = new_node,assignment
70,Gets the max value of the left branch,yes,  tmp_node = self.get_max(node.left) ,assignment
71,u must be deeper in the tree than v,yes,if level[u] < level[v]:,conditional
72,initializing with 0,yes,parent = [[0 for _ in range(max_node + 10)] for _ in range(20)],assignment
73,Only possible with an empty tree,yes,if self.label is None:,conditional
74,range in left child tree,yes,"return self._query_range(node.left, i, j)",return
75,None,yes,if not root:,conditional
76,return the parent of x,yes,  def find_set(x): x.parent = find_set(x.parent) return x.parent,method_declaration
77,hell's pointers D: don't DRY ,yes,self.values = [None] * self.size_table,assignment
78,Number of nodes in left subtree,yes,self.left_tree_size = 0,var_declaration
79,Update size,yes,self.size = self.size + other.size,assignment
80,Merging trees,yes,i = i.mergeTrees(i.parent),method_call
81,Updating self.bottom_root,yes,self.bottom_root = i,assignment
82,Update size,yes,self.size += 1,assignment
83,Update min_node,yes,self.min_node = None,assignment
84,Update bottom root,yes,self.bottom_root = self.bottom_root.parent,assignment
85,preorder,yes,heap_preOrder = [],var_declaration
86,check which child is larger than its parent,yes,if left_child is not None and self.h[left_child] > self.h[violation]:,conditional
87,Stores current size of heap.,yes,self.size = 0,var_declaration
88,Swap the element up ,yes,"def __swap_up(self, i: int) -> None: temporary = self.__heap[i] while i // 2 > 0: if self.__heap[i] > self.__heap[i // 2]: self.__heap[i] = self.__heap[i // 2] self.__heap[i // 2] = temporary i //= 2",method_declaration
89,Insert new element ,yes,"def insert(self, value: int) -> None: self.__heap.append(value) self.__size += 1 self.__swap_up(self.__size)",method_declaration
90,Swap the element down,yes,"def __swap_down(self, i: int) -> None:  while self.__size >= 2 * i: if 2 * i + 1 > self.__size: bigger_child = 2 * i else: if self.__heap[2 * i] > self.__heap[2 * i + 1]: bigger_child = 2 * i else: bigger_child = 2 * i + 1 temporary = self.__heap[i] if self.__heap[i] < self.__heap[bigger_child]: self.__heap[i] = self.__heap[bigger_child] self.__heap[bigger_child] = temporary i = bigger_child",method_declaration
91,Pop the root element,yes,  def pop(self) -> int: max_value = self.__heap[1] self.__heap[1] = self.__heap[self.__size] self.__size -= 1 self.__heap.pop() self.__swap_down(1) return max_value,method_declaration
92,Length of the array,yes,def __len__(self): return self.__size,method_declaration
93,create an instance of BinaryHeap,yes,binary_heap = BinaryHeap(),assignment
94,Generating Min-Heap from array,yes,"myMinHeap = MinHeap([r, b, a, x, e])",assignment
95,Before,yes,"print(""Min Heap - before decrease key"")",method_call
96,After,yes,for i in myMinHeap.heap: print(i),loop
97,insert at tail,yes,self.tail = new_node,assignment
98,This should happen,yes,assert True ,method_call
99,default first node,yes,delete_node = self.head,assignment
100,We have reached the end an no value matches,yes,"return ""No data matching given value""",return
101,This should not happen.,yes,assert False ,method_call
102,calculate the determinant of the matrix,yes,determinant = D(matrix[0][0]) * D(matrix[1][1]) - D(matrix[1][0]) * D(matrix[0][1]),assignment
103,"See ContinueCanonicalizationTest.test_multiple_continues for an example it's necessary to create guards for all enclosing affected blocks, not just that of the current block.",no,block.create_guard_next = True,assignment
104,"Place the outputs first, then sort lexicographically.",no,"scope_vars = sorted(scope_vars, key=lambda v: (v in input_only, v))",assignment
105,Converts conditional expressions to functional form.,no,"class ConditionalExpressionTransformer(converter.Base): def visit_IfExp(self, node): expr_repr = parser.unparse(node.test, include_encoding_marker=False).strip() return templates.replace_as_expression( template, test=node.test, true_expr=node.body, false_expr=node.orelse, expr_repr=gast.Constant(expr_repr, kind=None))",class_declaration
106,Variables not live into or out of the scope are considered local to the scope.,no,if s in live_in or s in live_out or s in nonlocals:,conditional
107,"Note: this information needs to be extracted before the body conversion that happens in the call to generic_visit below, because the conversion generates nodes that lack static analysis annotations.",no,"need_alias_in_body = self._determine_aliased_symbols( body_scope, defined_in)",method_call
108," Variable that are used or defined inside the loop, but not defined before entering the loop. Only simple variables must be defined. The composite ones will be implicitly checked at runtime.",no,undefined_lives = basic_loop_vars - defined_in,assignment
109,Edge case: a loop with just one directive statement would become empty.,no,if not node.body:,conditional
110,"Returns the options with which to create function scopes. Top-level function receive the options that were directly requested. All others receive the options corresponding to a recursive conversion. Note: this mainly controls the user_requested flag, which is important primarily because the FunctionScope context also creates a ControlStatusCtx(autograph=ENABLED) when user_requested is True. See function_wrappers.py.",no,"def _function_scope_options(self, fn_scope): if fn_scope.level == 2: return self.ctx.user.options return self.ctx.user.options.call_options()",method_declaration
111, Attempt to use a related name if one exists. Otherwise use something generic,no,"if anno.hasanno(target_node, anno.Basic.QN): target_name = anno.getanno(target_node, anno.Basic.QN).ssf() else: target_name = 'list_'",conditional
112," If the node definitely returns (e.g. it's a with statement with a return statement in it), then the current block also definitely returns.",no,    internal_use_only = False,conditional
113,Only the loads which existed in the original code are overloaded.,no,"if not anno.hasanno(node, anno.Static.ORIG_DEFINITIONS):",conditional
114,Tests whether a value is None or undefined. AutoGraph represents undefined symbols using special objects of type Undefined or UndefinedReturnValue. Args: value: value to test Returns: Boolean,no,"def _is_none_or_undef(value): return ((value is None) or isinstance(value, variables.UndefinedReturnValue) or isinstance(value, variables.Undefined))",method_declaration
115,This only happens when we could not infer a placeholder for the variable. The canonical case when that happens is when _placeholder_value couldnot infer a placeholder for it. That means it's of an unknown type or it's still undefined after staging one iteration.,no,if error_msg is not None:,conditional
116,Workaround for Dataset.reduce not allowing empty state tensors - create a dummy state variable that remains unused.,no,if not init_vars:,conditional
117,"TensorFlow: Multiple evaluations are acceptable in this case, so we're fine  with the re-evaluation of `test` that `_tf_while_stmt` will make.",no,if tensors.is_dense_tensor(init_test):,conditional
118,Triggered when we decided to test the op counts,no,self.check_op_count_after_iteration = False,assignment
119,Stage an iteration of the loop body in a temporary graph.,no,with func_graph.FuncGraph('tmp').as_default():,loop
120,Non-v2 while_loop unpacks the results when there is only one return value. This enforces consistency across versions.,no,while_loop_opts['return_same_structure'] = True,assignment
121,"Executes the eval function in the context of a specified function. When control flow is rewritten using functions, eval should use the variables found in the same block where it was called. That is equivalent to the innermost function call.",no,"def eval_in_original_context(f, args, caller_fn_scope): ctx_frame = _find_originating_frame(caller_fn_scope, innermost=True) args = ( args[0], ctx_frame.f_globals if len(args) < 2 else args[1], ctx_frame.f_locals if len(args) < 3 else args[2], ) return f(*args)",method_declaration
122,"Defaulting to flushing the console in graph mode, which helps reduce garbled output in IPython.",no,override_kwargs['flush'] = True,assignment
123,A dictionary with URL defaults that is added to each and every  URL that was defined with the blueprint.,no,self.url_defaults = dict(self.blueprint.url_values_defaults),assignment
124,Search for the most common names first.,no,"for attr_name in (""app"", ""application""):",loop
125,Update the app's debug flag through the descriptor so that other values repopulate as well.,no,app.debug = get_debug_flag(),assignment
126,"""Wraps a callback so that it's guaranteed to be executed with the script's application context.  If callbacks are registered directly to the ``app.cli`` object then they are wrapped with this function by default unless it's disabled.",no,"def with_appcontext(f): def decorator(__ctx, *args, **kwargs): with __ctx.ensure_object(ScriptInfo).load_app().app_context(): return __ctx.invoke(f, *args, **kwargs) return update_wrapper(decorator, f)",method_declaration
127,"Look up built-in and plugin commands, which should be available even if the app fails to load.",no,"rv = super().get_command(ctx, name)",method_call
128,"Like request context, app contexts can be pushed multiple times but there a basic ""refcount"" is enough to track them.",no,self._refcnt = 0,var_declaration
129,"Open the session at the moment that the request context is available.  This allows a custom open_session method to use the request context. Only  #  open a new session if this is the first time the request was pushed, otherwise stream_with_context loses the session.",no," if self.session is None: session_interface = self.app.session_interface self.session = session_interface.open_session(self.app, self.request)",method_call
130,get rid of circular dependencies at the end of the request so that we don't require the GC to be active.,no,"if clear_request: rv.request.environ[""werkzeug.request""] = None",assignment
131,The trick is to start the generator.  Then the code execution runs until the first dummy None is yielded at which point the context was already pushed.  This item is discarded.  Then when the iteration continues the real generator is executed.,no,wrapped_g = generator(),assignment
132,"If request specific information is available we have some extra features that support ""relative"" URLs.",no,if reqctx is not None:,conditional
133,Otherwise go with the url adapter from the appctx and make the URLs external by default.,no,else: url_adapter = appctx.url_adapter,conditional
134,"Safely join zero or more untrusted path components to a base directory to avoid escaping the base directory. :param directory: The trusted base directory. :param pathnames: The untrusted path components relative to the base directory. :return: A safe path, otherwise ``None``.",no,"def safe_join(directory, *pathnames): warnings.warn( ""'flask.helpers.safe_join' is deprecated and will be removed in"" "" 2.1. Use 'werkzeug.utils.safe_join' instead."", DeprecationWarning, stacklevel=2, ) path = werkzeug.utils.safe_join(directory, *pathnames) if path is None: raise NotFound() return path",method_declaration
135,if we don't have a filepath it might be because we are a namespace package.  In this case we pick the root path from the first module that is contained in our package.,no,if filepath is None:,conditional
136,"If the loader can tell us if something is a package, we can directly ask the loader.",no,"if hasattr(loader, ""is_package""):",conditional
137,zipimporter's loader.archive points to the .egg or .zip  archive filename is dropped in call to dirname below.,no,filename = loader.archive,assignment
138,In case the root module is a package we need to chop of the rightmost part. This needs to go through a helper function because of namespace packages.,no,"if _matching_loader_thinks_module_is_package(loader, root_mod_name):",conditional
139,UNIX like installations,no,"elif os.path.basename(parent).lower() == ""lib""",conditional
140,"send_file only knows to call get_send_file_max_age on the app, call it here so it works for blueprints too.",no," max_age = self.get_send_file_max_age(filename) return send_from_directory(self.static_folder, filename, max_age=max_age)",return
141,Serialize ``obj`` to a JSON-formatted string. The serialization will be configured according to the config associated with this EnvironBuilder's ``app``.,no,"def json_dumps(self, obj, **kwargs) kwargs.setdefault(""app"", self.app) return json_dumps(obj, **kwargs)",method_declaration
142,Normally the request context is preserved until the next request in the same thread comes. When the client exits we want to clean up earlier. Pop request contexts until the stack  is empty or a non-preserved one is found.,no,while True: top = _request_ctx_stack.top if top is not None and top.preserved: top.pop() else: break,loop
143," We attach the view class to the view function for two reasons: first of all it allows us to easily figure out what class-based view this thing came from, secondly it's also used for instantiating the view class so you can actually replace it with something else for testing purposes and debugging.",no,view.view_class = cls,assignment
144,If we have no method at all in there we don't want to add a method list. This is for instance the case for the base class or another subclass of a base method view that does not introduce new methods.,no,if methods: cls.methods = methods,conditional
145,If the request method is HEAD and we don't have a handler for it retry with GET.,no," if meth is None and request.method == ""HEAD"": meth = getattr(self, ""get"", None)",conditional
146," Maps (""app_label"", ""modelname"") tuples to lists of functions to be called when the corresponding model is ready. Used by this class's lazy_model_operation()` and `do_pending_operations()` methods.",no,self._pending_operations = defaultdict(list),assignment
147,Prevent reentrant calls to avoid running AppConfig.ready()  methods twice.,no,"raise RuntimeError(""populate() isn't reentrant"")",method_call
148,"If ""not ready"" is due to unconfigured settings, accessing INSTALLED_APPS raises a more helpful ImproperlyConfigured exception.",no,"settings.INSTALLED_APPS raise AppRegistryNotReady(""Apps aren't loaded yet."")",method_call
149,"Return a list of all installed models. By default, the following models aren't included: - auto-created models for many-to-many relations without an explicit intermediate table, - models that have been swapped out. Set the corresponding keyword argument to True to include such models.",no," def get_models(self, include_auto_created=False, include_swapped=False):  self.check_models_ready() result = [] for app_config in self.app_configs.values(): result.extend(app_config.get_models(include_auto_created, include_swapped)) return result",method_declaration
150,"Similar to get_model(), but doesn't require that an app exists with the given app_label. It's safe to call this method at import time, even while the registry is being populated.",no,"def get_registered_model(self, app_label, model_name): model = self.all_models[app_label].get(model_name.lower()) if model is None: raise LookupError( ""Model '%s.%s' not registered."" % (app_label, model_name)) return model",method_declaration
151,Call expire cache on each model. This will purge the relation tree and the fields cache.,no,self.get_models.cache_clear(),method_call
152, Circumvent self.get_models() to prevent that the cache is refilled. This particularly prevents that an empty value is cached while cloning.,no, for app_config in self.app_configs.values(): for model in app_config.get_models(include_auto_created=True):,conditional
153, This will be executed after the class corresponding to next_model has been imported and registered. The `func` attribute provides duck-type compatibility with partials.,no," def apply_next_model(model): next_function = partial(apply_next_model.func, model) self.lazy_model_operation(next_function, *more_models)",method_declaration
154,Number of seconds until a Request gives up on trying to read a request  body and aborts.,no,body_receive_timeout = 60,var_declaration
155,Size to chunk response bodies into for multiple response messages.,no,chunk_size = 2 ** 16,assignment
156,Receive the HTTP request body as a stream object.,no,body_file = await self.read_body(receive),method_call
157,We only assign to this when initialization is complete as it is used  as a flag for initialization being complete.,no,self._middleware_chain = handler,assignment
158,"If the response supports deferred rendering, apply template response middleware and then render the response",no,"if hasattr(response, 'render') and callable(response.render):",conditional
159,"If it is a synchronous view, run it in a subthread",no,if not asyncio.iscoroutinefunction(wrapped_callback):,conditional
160,"If the response supports deferred rendering, apply template response middleware and then render the response",no,"if hasattr(response, 'render') and callable(response.render):",conditional
161,"If PATH_INFO is empty (e.g. accessing the SCRIPT_NAME URL without a  trailing slash), operate as if '/' was requested.",no,path_info = get_path_info(environ) or '/',assignment
162,Non-ASCII values in the WSGI environ are arbitrarily decoded with ISO-8859-1. This is wrong for Django websites where UTF-8 is the default. Re-encode to recover the original bytestring.,no,return value.encode('iso-8859-1'),return
163,Indicates if the implemented serializer is only available for internal Django use.,no,internal_use_only = False,assignment
164,"If a URLRegexResolver doesn't have a namespace or app_name, it passes in an empty value.",no,self.app_names = [x for x in app_names if x] if app_names else [],assignment
165,Build a namespaced resolver for the given parent URLconf pattern. This makes it possible to have captured parameters in the parent  URLconf pattern,no,pattern = RegexPattern(ns_pattern),assignment
166,"As a performance optimization, if the given regex string is a regular  string (not a lazily-translated string proxy), compile it once and avoid per-language compilation.",no,"pattern = getattr(instance, self.attr)",assignment
167,"If there are any named groups, use those as kwargs, ignoring non-named groups. Otherwise, pass all non-named arguments as positional arguments.",no,"kwargs = match.groupdict() args = () if kwargs else match.groups() kwargs = {k: v for k, v in kwargs.items() if v is not None}",method_call
168,urlconf_name is the dotted Python path to the module defining urlpatterns. It may also be an object with an urlpatterns attribute or urlpatterns itself.,no,self.urlconf_name = urlconf_name,assignment
169, set of dotted paths to all functions and classes that are used in urlpatterns,no,self._callback_strs = set(),assignment
170,"The base_fields class attribute is the *class-wide* definition of fields. Because a particular *instance* of the class might want to alter self.fields, we create self.fields here by copying base_fields. Instances should always modify self.fields; they should not modify self.base_fields.",no,self.fields = copy.deepcopy(self.base_fields),assignment
171,"This can happen in the as_p() case (and possibly others that users write): if there are only top errors, we may not be able to conscript the last row for our purposes,  so insert a new, empty row.",no,"if not last_row.endswith(row_ender): last_row = (normal_row % { 'errors': '', 'label': '', 'field': '', 'help_text': '', 'html_class_attr': html_class_attr, 'css_classes': '', 'field_name': '', }) output.append(last_row)",conditional
172,"value_from_datadict() gets the data from the data dictionaries. Each widget type knows how to retrieve its own data, because some widgets split data over several HTML fields.",no,"if field.disabled: value = self.get_initial_for_field(field, name) else: value = field.widget.value_from_datadict(self.data, self.files, self.add_prefix(name))",conditional
173,"For convenience we create empty caches even if they are not used. A note about caching: if use_caching is defined, then for each distinct sender we cache the receivers that sender has in 'sender_receivers_cache'. The cache is cleaned when .connect() or .disconnect() is called and populated on send().",no,self.sender_receivers_cache = weakref.WeakKeyDictionary() if use_caching else {},method_call
174,"Connect receiver to sender for signal. Arguments: receiver A function or an instance method which is to receive signals. Receivers must be hashable objects. If weak is True, then receiver must be weak referenceable. Receivers must be able to accept keyword arguments. If a receiver is connected with a dispatch_uid argument, it will not be added if another receiver was already connected with that dispatch_uid. sender The sender to which the receiver should respond. Must either be a Python object, or None to receive events from any sender. weak Whether to use weak references to the receiver. By default, the module will attempt to use weak references to the receiver objects. If this parameter is false, then strong references will be used. dispatch_uid An identifier used to uniquely identify a particular instance of a receiver. This will usually be a string, though it may be anything hashable.",no,"def connect(self, receiver, sender=None, weak=True, dispatch_uid=None): from django.conf import settings if settings.configured and settings.DEBUG: assert callable(receiver), ""Signal receivers must be callable."" if not func_accepts_kwargs(receiver): raise ValueError(""Signal receivers must accept keyword arguments (**kwargs)."") if dispatch_uid: lookup_key = (dispatch_uid, _make_id(sender)) else: lookup_key = (_make_id(receiver), _make_id(sender)) if weak: ref = weakref.ref receiver_object = receiver if hasattr(receiver, '__self__') and hasattr(receiver, '__func__'): ref = weakref.WeakMethodreceiver_object = receiver.__self__ receiver = ref(receiver) weakref.finalize(receiver_object, self._remove_receiver) with self.lock: self._clear_dead_receivers() if not any(r_key == lookup_key for r_key, _ in self.receivers): self.receivers.append((lookup_key, receiver)) self.sender_receivers_cache.clear()",method_declaration
175,"Disconnect receiver from sender for signal. If weak references are used, disconnect need not be called. The receiver will be removed from dispatch automatically. Arguments: receiver The registered receiver to disconnect. May be none if dispatch_uid is specified. sender The registered sender to disconnect dispatch_uid the unique identifier of the receiver to disconnect",no,"def disconnect(self, receiver=None, sender=None, dispatch_uid=None): if dispatch_uid: lookup_key = (dispatch_uid, _make_id(sender)) else: lookup_key = (_make_id(receiver), _make_id(sender)) disconnected = False with self.lock: self._clear_dead_receivers() for index in range(len(self.receivers)): (r_key, _) = self.receivers[index] if r_key == lookup_key: disconnected = True del self [index] break self.sender_receivers_cache.clear() return disconnected",method_declaration
176, We could end up here with NO_RECEIVERS even if we do check this case in .send() prior to calling _live_receivers() due to concurrent .send() call.,no,if receivers is NO_RECEIVERS:,conditional
177,"Mark that the self.receivers list has dead weakrefs. If so, we will clean those up in connect, disconnect and _live_receivers while holding self.lock. Note that doing the cleanup here isn't a good  idea, _remove_receiver() will be called as side effect of garbage  collection, and so the call can happen while we are already holding self.lock.",no,self._dead_receivers = True,assignment
178,"Don't render the HTML 'required' attribute as it may cause incorrect validation for extra, optional, and deleted forms in the formset.",no,"'use_required_attribute': False,",assignment
179,List comprehension ensures is_valid() is called for all forms. Forms due to be deleted shouldn't cause the formset to be invalid.,no,forms_valid = all([ form.is_valid() for form in self.forms if not (self.can_delete and self._should_delete_form(form)) ]),assignment
180,"absolute_max is a hard limit on forms instantiated, to prevent memory-exhaustion attacks. Default to max_num + DEFAULT_MAX_NUM  (which is 2 * DEFAULT_MAX_NUM if max_num is None in the first place).",no,if absolute_max is None: absolute_max = max_num + DEFAULT_MAX_NUM,conditional
181,Add a flag to define which application module file is tested. This is set as an 'arg' in the build target to guarantee that it only triggers the tests of the application models in the module if that module file has been modified.,no,"FLAGS = flags.FLAGS flags.DEFINE_string('module', None, 'Application module used in this test.')",method_call
182,In debug mode we're replacing the files multidict with an ad-hoc subclass that raises a different error for key errors.,no,"if ( current_app and current_app.debug and self.mimetype != ""multipart/form-data"" and not self.files ): from .debughelpers import attach_enctype_error_multidict attach_enctype_error_multidict(self)",conditional
183,"We attach the view class to the view function for two reasons: first of all it allows us to easily figure out what class-based view this thing came from, secondly it's also used for instantiating the view class so you can actually replace it with something else for testing purposes and debugging.",no,view.view_class = cls,assignment
184,If we have no method at all in there we don't want to add a method list. This is for instance the case for the base class or another subclass of a base method view that does not introduce  new methods.,no,if methods: cls.methods = methods,conditional
185,Renders a template from the given template source string with the given context. Template variables will be autoescaped. :param source: the source code of the template to be rendered :param context: the variables that should be available in the context of the template.,no,"def render_template_string(source, **context): ctx = _app_ctx_stack.top ctx.app.update_template_context(context) return _render(ctx.app.jinja_env.from_string(source), context, ctx.app)",method_declaration
186,Core signals.  For usage examples grep the source code or consult the API documentation in docs/api.rst as well as docs/signals.rst,no,"template_rendered = _signals.signal(""template-rendered"")",assignment
187,"When data is changed, this is set to ``True``. Only the session  dictionary itself is tracked; if the session contains mutable  data (for example a nested dict) then this must be set to ``True`` manually when modifying that data. The session cookie  will only be written to the response if this is ``True``.",no,modified = False,assignment
188," if this is not an ip and app is mounted at the root, allow subdomain matching by adding a '.' prefix",no,"if self.get_cookie_path(app) == ""/"" and not ip:",conditional
189,The trick is to start the generator.  Then the code execution runs until the first dummy None is yielded at which point the context was already  pushed.  This item is discarded.  Then when the iteration continues the real generator is executed.,no,wrapped_g = generator(),method_call
190,"For compatibility with low-level network APIs (with 32-bit integers), the chunk size should be < 2^31, but still divisible by 4.",no,self._chunk_size = min([2 ** 31 - 4] + possible_sizes),assignment
191,We run this at the beginning of the next loop since we cannot be sure a file is complete until we hit the next boundary/part of the multipart content.,no,"self.handle_file_complete(old_field_name, counters)",method_call
192," Stream at beginning of header, look for end of header and parse it if found. The header must fit within one chunk",no,chunk = stream.read(max_header_size),assignment
193,"If location starts with '//' but has no netloc, reuse the schema and netloc from the current request. Strip the double slashes and continue as if it wasn't specified.",no,if location.startswith('//'):,conditional
194,"Join the constructed URL with the provided location, which allows the provided location to apply query strings to the base path.",no,"location = urljoin(self._current_scheme_host + self.path, location)",assignment
195,"The [2:-2] ranges below strip off *_TAG_START and *_TAG_END. We could do len(BLOCK_TAG_START) to be more ""correct"", but we've hard-coded the 2s here for performance. And it's not like  the TAG_START values are going to change anytime, anyway.",no,block_content = token_string[2:-2].strip(),assignment
196,Add the token to the command stack. This is used for error messages if further parsing fails due to an unclosed block tag.,no,"self.command_stack.append((command, token))",method_call
197,"If this block's parent doesn't have an extends node it is the root, and its block nodes also need to be added to the block context.",no,for node in compiled_parent.nodelist:,loop
198,"It would seem obvious to call these next two members 'template' and 'context', but those names are reserved as part of the test Client API. To avoid the name collision, we use different names.",no,self.template_name = template,assignment
199," _request stores the current request object in subclasses that know about requests, like TemplateResponse. It's defined in the base class to minimize code duplication. It's called self._request because self.request gets overwritten by django.test.client.Client. Unlike template_name and context_data,  _request should not be considered part of the public API.",no,self._request = None,var_declaration
